From db6d689ee54ea33dd1f29a6ebde756aaeb55fdd2 Mon Sep 17 00:00:00 2001
From: LucasEby <lucaseby@outlook.com>
Date: Tue, 18 Feb 2025 18:01:53 -0500
Subject: [PATCH 052/150] Cleaned up code a bit. Will add Vikram's suggestions
 in Slack next

---
 .../perception/pedestrian_detection.py        | 34 +++----------------
 1 file changed, 5 insertions(+), 29 deletions(-)

diff --git a/GEMstack/onboard/perception/pedestrian_detection.py b/GEMstack/onboard/perception/pedestrian_detection.py
index f78b0c68..bf4b10e1 100644
--- a/GEMstack/onboard/perception/pedestrian_detection.py
+++ b/GEMstack/onboard/perception/pedestrian_detection.py
@@ -242,7 +242,6 @@ class PedestrianDetector2D(Component):
         if len(pedestrians_3d_pts) != num_objs:
             raise Exception('Perception - Camera detections, points clusters num. mismatch')
         
-        # TODO: CONVERT FROM LIDAR FRAME TO VEHICLE FRAME HERE (vehicle frame is center of rear axle at vehicle's current location)
         # If in vehicle frame, transform centers from top_lidar frame to vehicle frame
         # Need to transform the center point one by one since matrix op can't deal with empty points
         if self.vehicle_frame:
@@ -260,35 +259,15 @@ class PedestrianDetector2D(Component):
         #       or at least {track_ids: centers/pts/etc}
         # TODO: Combine funcs for efficiency in C.
         #       Separate numpy prob still faster for now
-        obj_centers = self.find_centers(pedestrians_3d_pts)
+        obj_centers = self.find_centers(pedestrians_3d_pts) # Centers are calculated in current vehicle frame here (center of rear axle) 
         obj_dims = self.find_dims(pedestrians_3d_pts)
 
         # TODO: CONVERT FROM VEHICLE FRAME TO START FRAME HERE
-        # Then compare previous and current agents with the same id to calculate velocity
-        # for idx in range(len(obj_centers)):
-        #     print(obj_centers[idx])
-        #     print(obj_dims[idx])
         self.find_vels_and_ids(obj_centers, obj_dims)
-        # obj_vels = self.find_vels(track_ids, obj_centers)
-
-        # # Update Current AgentStates
-        # for ind in range(num_objs):
-        #     obj_center = (None, None, None) if obj_centers[ind].size == 0 else obj_centers[ind]
-        #     obj_dim = (None, None, None) if obj_dims[ind].size == 0 else obj_dims[ind]
-        #     self.current_agents[track_ids[ind]] = (
-        #         AgentState(
-        #             track_id = track_ids[ind],
-        #             pose=ObjectPose(t=0, x=obj_center[0], y=obj_center[1], z=obj_center[2] ,yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
-        #             # (l, w, h)
-        #             # TODO: confirm (z -> l, x -> w, y -> h)
-        #             dimensions=(obj_dim[0], obj_dim[1], obj_dim[2]),  
-        #             outline=None,
-        #             type=AgentEnum.PEDESTRIAN,
-        #             activity=AgentActivityEnum.MOVING,
-        #             velocity= None if obj_vels[track_ids[ind]].size == 0 else tuple(obj_vels[track_ids[ind]]),
-        #             yaw_rate=0
-        #         ))
             
+    # TODO: Refactor to make more efficient
+    # TODO: Moving Average across last N iterations pos/vel? Less spurious vals
+    # TODO Fix velocity calculation to calculate in ObjectFrameEnum.START
     def find_vels_and_ids(self, obj_centers: List[np.ndarray], obj_dims: List[np.ndarray]):
         # Gate to check whether dims and centers are empty (will happen if no pedestrians are scanned):
         if ((len(obj_dims) == 1 or len(obj_centers) == 1) and (obj_centers[0].size == 0 or obj_dims[0].size == 0)):
@@ -304,14 +283,11 @@ class PedestrianDetector2D(Component):
         
         new_prev_agents = {} # Stores current agents in START frame for next time through (since 
                              # planning wants us to send them agents in CURRENT frame)
-        # Object not seen -> velocity = None
-        vels = defaultdict(lambda: np.array(())) # None is faster, np.array matches other find_ methods.
 
-        # THIS ASSUMES EVERYTHING IS IN THE SAME FRAME WHICH WOULD WORK FOR STATIONARY CAR.
-        # TODO: NEED TO STORE AND INCORPORATE TRANSFORMS SOMEHOW TO DEAL WITH MOVING CAR CASE
         assigned = False
         num_pairings = len(obj_centers)
 
+        # TODO: NEED TO STORE AND INCORPORATE TRANSFORMS SOMEHOW TO DEAL WITH MOVING CAR CASE
         converted_centers = obj_centers # TODO: REPLACE WITH THIS: self.convert_vehicle_frame_to_start_frame(obj_centers)
 
         # Loop through the indexes of the obj_center and obj_dim pairings
-- 
2.38.1

