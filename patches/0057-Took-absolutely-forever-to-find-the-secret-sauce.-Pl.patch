From a18d1876b154329aedfd71e4487cef4da8a141a5 Mon Sep 17 00:00:00 2001
From: LucasEby <lucaseby@outlook.com>
Date: Tue, 18 Feb 2025 21:50:44 -0500
Subject: [PATCH 057/150] Took absolutely forever to find the secret sauce.
 Please excuse the mess

---
 .../perception/pedestrian_detection.py        | 80 +++++++++++++------
 1 file changed, 54 insertions(+), 26 deletions(-)

diff --git a/GEMstack/onboard/perception/pedestrian_detection.py b/GEMstack/onboard/perception/pedestrian_detection.py
index 2c24f3be..381075c9 100644
--- a/GEMstack/onboard/perception/pedestrian_detection.py
+++ b/GEMstack/onboard/perception/pedestrian_detection.py
@@ -114,6 +114,10 @@ class PedestrianDetector2D(Component):
         self.prev_time = None # Time in seconds since last scan for basic velocity calculation
         self.curr_time = None # Time in seconds of current scan for basic velocity calculation
         self.id_tracker = IdTracker()
+        
+        # Update function variables
+        self.t_start = None # datetime.now() # Estimated start frame time
+        self.start_pose_abs = None
     
     def init_debug(self,) -> None:
          # Debug Publishers
@@ -123,6 +127,10 @@ class PedestrianDetector2D(Component):
         self.pub_image = rospy.Publisher("/camera/image_detection", Image, queue_size=1)
 
     def update(self, vehicle : VehicleState) -> Dict[str,AgentState]:
+        if self.t_start is None:
+            self.t_start = self.vehicle_interface.time()
+        if self.start_pose_abs is None:
+            self.start_pose_abs = vehicle.pose
         return self.current_agents
 
     # TODO: Improve Algo Knn, ransac, etc.
@@ -148,21 +156,21 @@ class PedestrianDetector2D(Component):
     #            Work towards own tracking class instead of simple YOLO track?
     #            Fix division by time
     # ret: Dict[track_id: vel[x, y, z]]
-    def find_vels(self, track_ids: List[int], obj_centers: List[np.ndarray], obj_dims: List[np.ndarray]) -> Dict[int, np.ndarray]:
-        # Object not seen -> velocity = None
-        track_id_center_map = dict(zip(track_ids, obj_centers))
-        vels = defaultdict(lambda: np.array(())) # None is faster, np.array matches other find_ methods.
-
-        for prev_track_id, prev_agent in self.prev_agents.items():
-            if prev_track_id in track_ids:
-                # TODO: Add prev_agents to memory to avoid None velocity
-                # We should only be missing prev pose on first sight of track_id Agent.
-                # print("shape 1: ", track_id_center_map[prev_agent.track_id])
-                # print("shape 2: ", np.array([prev_agent.pose.x, prev_agent.pose.y, prev_agent.pose.z]))
-                # prev can be 3 separate Nones, current is just empty array... make this symmetrical
-                if prev_agent.pose.x and prev_agent.pose.y and prev_agent.pose.z and track_id_center_map[prev_agent.track_id].shape == 3:
-                    vels[prev_track_id] = (track_id_center_map[prev_track_id] - np.array([prev_agent.pose.x, prev_agent.pose.y, prev_agent.pose.z])) / (self.curr_time - self.prev_time)
-        return vels
+    # def find_vels(self, track_ids: List[int], obj_centers: List[np.ndarray], obj_dims: List[np.ndarray]) -> Dict[int, np.ndarray]:
+    #     # Object not seen -> velocity = None
+    #     track_id_center_map = dict(zip(track_ids, obj_centers))
+    #     vels = defaultdict(lambda: np.array(())) # None is faster, np.array matches other find_ methods.
+
+    #     for prev_track_id, prev_agent in self.prev_agents.items():
+    #         if prev_track_id in track_ids:
+    #             # TODO: Add prev_agents to memory to avoid None velocity
+    #             # We should only be missing prev pose on first sight of track_id Agent.
+    #             # print("shape 1: ", track_id_center_map[prev_agent.track_id])
+    #             # print("shape 2: ", np.array([prev_agent.pose.x, prev_agent.pose.y, prev_agent.pose.z]))
+    #             # prev can be 3 separate Nones, current is just empty array... make this symmetrical
+    #             if prev_agent.pose.x and prev_agent.pose.y and prev_agent.pose.z and track_id_center_map[prev_agent.track_id].shape == 3:
+    #                 vels[prev_track_id] = (track_id_center_map[prev_track_id] - np.array([prev_agent.pose.x, prev_agent.pose.y, prev_agent.pose.z])) / (self.curr_time - self.prev_time)
+    #     return vels
     
     # TODO: Separate debug/viz class, bbox and 2d 3d points funcs 
     def viz_object_states(self, cv_image, boxes, extracted_pts_all):
@@ -287,7 +295,7 @@ class PedestrianDetector2D(Component):
         assigned = False
         num_pairings = len(obj_centers)
 
-        # TODO: NEED TO STORE AND INCORPORATE TRANSFORMS SOMEHOW TO DEAL WITH MOVING CAR CASE
+        # TODO: NEED TO STORE AND INCORPORATE TRANSFORMS SOMEHOW TO DEAL WITH MOVING CAR CASE        
         converted_centers = obj_centers # TODO: Add this in when finished self.convert_vehicle_frame_to_start_frame(obj_centers)
 
         # Loop through the indexes of the obj_center and obj_dim pairings
@@ -312,7 +320,7 @@ class PedestrianDetector2D(Component):
                     self.current_agents[prev_id] = (
                         AgentState(
                             track_id = prev_id,
-                            pose=ObjectPose(t=0, x=obj_centers[idx][0], y=obj_centers[idx][1], z=obj_centers[idx][2], yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
+                            pose=ObjectPose(t=(self.curr_time-self.t_start).total_seconds(), x=obj_centers[idx][0], y=obj_centers[idx][1], z=obj_centers[idx][2], yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
                             # (l, w, h)
                             # TODO: confirm (z -> l, x -> w, y -> h)
                             dimensions=(obj_dims[idx][0], obj_dims[idx][1], obj_dims[idx][2]),  
@@ -325,7 +333,7 @@ class PedestrianDetector2D(Component):
                     new_prev_agents[prev_id] = (
                         AgentState(
                             track_id = prev_id,
-                            pose=ObjectPose(t=0, x=converted_centers[idx][0], y=converted_centers[idx][1], z=converted_centers[idx][2], yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
+                            pose=ObjectPose(t=(self.curr_time-self.t_start).total_seconds(), x=converted_centers[idx][0], y=converted_centers[idx][1], z=converted_centers[idx][2], yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
                             # (l, w, h)
                             # TODO: confirm (z -> l, x -> w, y -> h)
                             dimensions=(obj_dims[idx][0], obj_dims[idx][1], obj_dims[idx][2]),  
@@ -341,11 +349,11 @@ class PedestrianDetector2D(Component):
             # If not assigned:
             if not assigned:
                 # Set velocity to 0 and assign the new agent a new id with IdTracker
-                id = self.id_tracker.get_new_id()
+                id = "ped" + str(self.id_tracker.get_new_id())
                 self.current_agents[id] = (
                     AgentState(
                         track_id = id,
-                        pose=ObjectPose(t=0, x=obj_centers[idx][0], y=obj_centers[idx][1], z=obj_centers[idx][2] ,yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
+                        pose=ObjectPose(t=(self.curr_time-self.t_start).total_seconds(), x=obj_centers[idx][0], y=obj_centers[idx][1], z=obj_centers[idx][2] ,yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
                         # (l, w, h)
                         # TODO: confirm (z -> l, x -> w, y -> h)
                         dimensions=(obj_dims[idx][0], obj_dims[idx][1], obj_dims[idx][2]),  
@@ -358,7 +366,7 @@ class PedestrianDetector2D(Component):
                 new_prev_agents[id] = (
                     AgentState(
                         track_id = id,
-                        pose=ObjectPose(t=0, x=converted_centers[idx][0], y=converted_centers[idx][1], z=converted_centers[idx][2] ,yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
+                        pose=ObjectPose(t=(self.curr_time-self.t_start).total_seconds(), x=converted_centers[idx][0], y=converted_centers[idx][1], z=converted_centers[idx][2] ,yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
                         # (l, w, h)
                         # TODO: confirm (z -> l, x -> w, y -> h)
                         dimensions=(obj_dims[idx][0], obj_dims[idx][1], obj_dims[idx][2]),  
@@ -394,11 +402,31 @@ class PedestrianDetector2D(Component):
         )
 
     def convert_vehicle_frame_to_start_frame(self, vehicle_states: List[AgentState]) -> List[AgentState]:
-        # num_states = len(vehicle_states)
-        # for idx in num_states:
-        #     num_states[idx].to_frame()
-        pass
-
+        num_states = len(vehicle_states)
+        for idx in num_states:
+            vehicle_states[idx] = vehicle_states[idx].to_frame(frame=ObjectFrameEnum.START, current_pose=current_obj_pose, start_pose_abs=self.start_pose_abs)
+
+        # current_obj_pose = ObjectPose(
+        #         frame=ObjectFrameEnum.CURRENT, 
+        #         t=(self.curr_time-self.t_start).total_seconds(), 
+        #         x=vehicle_states[idx].pose.x, 
+        #         y=vehicle_states[idx].pose.y, 
+        #         z=vehicle_states[idx].pose.z
+        #     )
+        # vehicle_states[0] = vehicle_states[0].to_frame(frame=ObjectFrameEnum.START, current_pose=current_obj_pose, start_pose_abs=self.start_pose_abs)
+        # # start_obj_pose???
+        # state = AgentState(
+        #                     track_id =0,
+        #                     pose=ObjectPose(t=(self.curr_time-self.t_start).total_seconds(), x=obj_centers[idx][0], y=obj_centers[idx][1], z=obj_centers[idx][2], yaw=0,pitch=0,roll=0,frame=ObjectFrameEnum.CURRENT),
+        #                     # (l, w, h)
+        #                     # TODO: confirm (z -> l, x -> w, y -> h)
+        #                     dimensions=(obj_dims[idx][0], obj_dims[idx][1], obj_dims[idx][2]),  
+        #                     outline=None,
+        #                     type=AgentEnum.PEDESTRIAN,
+        #                     activity=AgentActivityEnum.STOPPED if np.all(vel == 0) else AgentActivityEnum.MOVING,
+        #                     velocity=None if vel.size == 0 else tuple(vel),
+        #                     yaw_rate=0
+        #                 )
 
     def ouster_oak_callback(self, rgb_image_msg: Image, lidar_pc2_msg: PointCloud2):
         # Update times for basic velocity calculation
-- 
2.38.1

